{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Title</font> : KOSPI Index Predicting Project<br>\n",
        "Participants</font> : <blockquote> <br>Park Su Young (mak8mgt07@naver.com, https://github.com/vvvv1111vvvv)<br>Lee Donghwan(hwany1227@gmail.com, <br>www.linkedin.com/in/donghwanlee7)</blockquote><br>\n",
        "ate Created</font> : 2022.06.28 ~ 2022.07.18<br>\n",
        "Roles</font> : <br>\n",
        "<blockquote> <br>\n",
        "Park Su Young : KOSPI Index Crawling/Processing,  Data Correlation Analysis,  Deep Learning & Performance Analysis<br><br>\n",
        " Lee Donghwan : Building Macroeconomics Index DB, Implementing Risk Analysis.\n",
        "</blockquote>\n",
        "Purpose</font> : Analyze the correlation between the KOSPI index and economic indicators and use deep learning to predict the future KOSPI index.<br>\n",
        "\n",
        "Method</font>: <br>\n",
        "<blockquote>(1) Crawl economic indicators on the Bank of Korea's web page and process them.<br>\n",
        "(2) Crawls the KOSPI index on the Naver finance and processes it<br>\n",
        "(3) Collect and Organize the data obtained in the previous step based on the business days between 2015.07.24 and 2022.07.01\"<br>\n",
        "(4) Add GJR-GARCH(p,q) model value to the summarized data<br>\n",
        "(5) Normalize the organized data<br>\n",
        "(6) Analyze the organized data to identify the correlation,and modify the data structure to predict \"1 day\" with \"5 days\". <blockquote>train_date: \"2015.07.24 ~ 2021.06.30\" <br>test_date: \"2021.07.01 ~ 2022.07.01\"</blockquote><br>\n",
        "(7) Design Multi-layers with LSTM, Dense. Train Data with the Model. Compare the actual KOSPI value of 2021.07.01~2022.07.01 period with the predicted KOSPI value(1 day will be estimated by 5 days at CNN model), feature comparing graph and predictive performance index.\n",
        "<br><br><br>\n",
        "\n"
      ],
      "metadata": {
        "id": "0q5-QBr0k-iF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "제목</font>: KOSPI 예측 프로젝트 <br>\n",
        "작성자</font>: <blockquote><br>박수영 (mak8mgt07@naver.com, https://github.com/vvvv1111vvvv)<br>\n",
        "이동환(hwany1227@gmail.com,\n",
        "www.linkedin.com/in/donghwanlee7)\n",
        "</blockquote><br>\n",
        "\n",
        "작성일</font>: 2022.06.28 ~ 2022.07.18<br>\n",
        "역할</font>: <br>\n",
        "<blockquote> <br>\n",
        "박수영: KOSPI인덱스 크롤링/가공, 데이터 상관관계 분석, 딥러닝 학습 및 성능분석<br>\n",
        "이동환: 거시경제지표 DB 구축, GJR-GARCH(1,1) 모형을 이용한 리스크 분석\n",
        "\n",
        "</blockquote>\n",
        "목적</font>: KOSPI 지수와 경제지표 사이의 상관관계를 분석하고, 딥러닝을 활용해 KOSPI지수를 예측한다. <br>\n",
        "방법</font>: <br>\n",
        "<blockquote>(1) 한국은행 웹페이지에서 경제지표를 크롤링 한 뒤 가공한다.<br>\n",
        "(2) Naver finance 에서 KOSPI 인덱스를 크롤링 한 뒤 가공한다.<br>\n",
        "(3) 이전 단계에서 획득한 데이터를 취합하고, \"2015.07.24 ~ 2022.07.01\"동안의 영업일을 기준으로 정리한다.<br>\n",
        "(4) 정리한 데이터에 GJR-GARCH(p,q) 모형값을 추가한다.<br>\n",
        "(5) 정리한 데이터를 정규화한다.<br>\n",
        "(6) 정리한 데이터를 분석하여 상관관계를 파악하고, \"5 days\"로 \"1day\"를 예측하도록 데이터 구조를 수정한다. <blockquote>train_date: \"2015.07.24 ~ 2021.06.30\" <br>test_date: \"2021.07.01 ~ 2022.07.01\"</blockquote><br>\n",
        "(7) LSTM과 Dense로 다층 Layer를 설계하고 train 데이터를 학습시킨다. 그 다음, 'adam'을 사용해 \"2021.07.01~2022.07.01 기간의 실제 KOSPI값\"과, \"실제 5day로 추정한 1day씩의 예측 KOSPI값\"을 비교하여 그래프와 예측성능 지표로 출력한다. \n"
      ],
      "metadata": {
        "id": "8gRMy7aTM421"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "BHED-PEAl13L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX1evZdJ3jw0"
      },
      "source": [
        "# **1. 경제지표 API 크롤링 (출처 : 한국은행) (Economic Indicators Crawling)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6hP3W1v3qpJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "#100대 통계지표 요청 url\n",
        "url = \"http://ecos.bok.or.kr/api/KeyStatisticList/R0FQKORGKXRKG6CIJS2V/json/kr/1/100/\"\n",
        "resp = requests.get(url)\n",
        "data = resp.json()\n",
        "rdata = data['KeyStatisticList']['row']\n",
        "\n",
        "df = pd.DataFrame(rdata)\n",
        "indice = df.KEYSTAT_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeAs010VctpK"
      },
      "source": [
        "API\n",
        " 한국은행 ECOS API (인증키 : R0FQKORGKXRKG6CIJS2V )\n",
        "\n",
        "raw 데이터 관련\n",
        " info) 주가가 5만-10만원인 종목은 100원, 10만-50만원인 종목은 500원 간격으로 거래된다. <br>\n",
        " info) 한국은행 경제변수 - 분기별/월별/일별 자료 데이터.. 데이터 전처리시 참고 <br>\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gugWW9oy0RjS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10e2c57f-aeaa-4e60-a74d-9ff25b0019a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              명칭      코드명 사이클         코드1   코드2\n",
              "0         GDP-총액  200Y002   Q       10111   NaN\n",
              "1      GDP-비농림어업  200Y002   Q       10112   NaN\n",
              "2       GDP-농림어업  200Y002   Q       10113   NaN\n",
              "3         GDP-제조  200Y002   Q       10114   NaN\n",
              "4         GDP-건설  200Y002   Q       10115   NaN\n",
              "5       GDP-서비스업  200Y002   Q       10116   NaN\n",
              "6        GDP-ICT  200Y002   Q       10117   NaN\n",
              "7       GDP-비ICT  200Y002   Q       10118   NaN\n",
              "8       GDP-민간소비  200Y002   Q       10122   NaN\n",
              "9          투자-설비  200Y002   Q       10123   NaN\n",
              "10         투자-건설  200Y002   Q       10124   NaN\n",
              "11      투자-수출-재화  200Y002   Q       10125   NaN\n",
              "12      투자-수입-내수  200Y002   Q       10126   NaN\n",
              "13        환율-USD  731Y001   D     0000001   NaN\n",
              "14        환율-CNY  731Y001   D     0000053   NaN\n",
              "15        환율-JPY  731Y001   D     0000002   NaN\n",
              "16        환율-EUR  731Y001   D     0000003   NaN\n",
              "17        물가-CPI  901Y009   M           0   NaN\n",
              "18   물가-GDP디플레이터  200Y011   Q        1400   NaN\n",
              "19       심리-경제심리  513Y001   M       E1000   NaN\n",
              "20       심리-뉴스심리  521Y001   D        A001   NaN\n",
              "21       통화-본원통화  102Y002   M        ABA1   NaN\n",
              "22         통화-M2  101Y004   M      BBHA00   NaN\n",
              "23       금리-기준금리  722Y001   D     0101000   NaN\n",
              "24      금리-콜(1일)  817Y002   D   010101000   NaN\n",
              "25    금리-국고채(3년)  817Y002   D   010200000   NaN\n",
              "26   금리-국고채(10년)  817Y002   D   010210000   NaN\n",
              "27       대출-예금은행  121Y006   M    BECBLA01   NaN\n",
              "28        대출-대기업  121Y006   M  BECBLA0201   NaN\n",
              "29         대출-가계  121Y006   M    BECBLA03   NaN\n",
              "30        대출-주담대  121Y006   M  BECBLA0302   NaN\n",
              "31  주식시장-KOSPI지수  802Y001   D     0001000   NaN\n",
              "32      주식시장-거래량  802Y001   D     0002000   NaN\n",
              "33     주식시장-거래대금  802Y001   D     0003000   NaN\n",
              "34   주식시장-외국인순매수  802Y001   D     0030000   NaN\n",
              "35        재정-총수입  901Y013   M         A01   NaN\n",
              "36        재정-소득세  901Y013   M     A010101   NaN\n",
              "37     재정-재화/용역세  901Y013   M     A010103   NaN\n",
              "38         재정-관세  901Y013   M     A010104   NaN\n",
              "39        재정-총지출  901Y013   M         B01   NaN\n",
              "40        재정-보조금  901Y013   M    B0101031   NaN\n",
              "41       재정-경상지출  901Y013   M     B010101   NaN\n",
              "42      국민소득-GDP  200Y005   Q        1400   NaN\n",
              "43      국민소득-GNI  200Y006   Q        1600   NaN\n",
              "44    국제금리-미국6개월  902Y001   M     1020302   NaN\n",
              "45     국제금리-미국5년  902Y001   M     1020402   NaN\n",
              "46    국제금리-미국10년  902Y001   M     1020403   NaN\n",
              "47   국제주가지수-다우존스  902Y002   M     3020101   NaN\n",
              "48    국제주가지수-나스닥  902Y002   M     3020103   NaN\n",
              "49    국제주가지수-니케이  902Y002   M     3020108   NaN\n",
              "50     국제주가지수-항셍  902Y002   M     3020114   NaN\n",
              "51     국제주가지수-중국  902Y002   M     3020115   NaN\n",
              "52     국제주가지수-독일  902Y002   M     3020106   NaN\n",
              "53        노동-고용률  901Y027   M        I61E  I28A\n",
              "54    노동-경제활동참가율  901Y027   M        I61D  I28A\n",
              "55        노동-실업률  902Y021   M         KOR   NaN\n",
              "56      노동-미국실업률  902Y021   M         USA   NaN\n",
              "57       금리-미국금리  902Y001   M     1020302   NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cc0a3a5-41c2-4684-b99c-366e600a4128\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>명칭</th>\n",
              "      <th>코드명</th>\n",
              "      <th>사이클</th>\n",
              "      <th>코드1</th>\n",
              "      <th>코드2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GDP-총액</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10111</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GDP-비농림어업</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10112</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GDP-농림어업</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10113</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GDP-제조</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10114</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GDP-건설</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GDP-서비스업</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10116</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GDP-ICT</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10117</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GDP-비ICT</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10118</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GDP-민간소비</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10122</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>투자-설비</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10123</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>투자-건설</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10124</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>투자-수출-재화</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10125</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>투자-수입-내수</td>\n",
              "      <td>200Y002</td>\n",
              "      <td>Q</td>\n",
              "      <td>10126</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>환율-USD</td>\n",
              "      <td>731Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0000001</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>환율-CNY</td>\n",
              "      <td>731Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0000053</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>환율-JPY</td>\n",
              "      <td>731Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0000002</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>환율-EUR</td>\n",
              "      <td>731Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0000003</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>물가-CPI</td>\n",
              "      <td>901Y009</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>물가-GDP디플레이터</td>\n",
              "      <td>200Y011</td>\n",
              "      <td>Q</td>\n",
              "      <td>1400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>심리-경제심리</td>\n",
              "      <td>513Y001</td>\n",
              "      <td>M</td>\n",
              "      <td>E1000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>심리-뉴스심리</td>\n",
              "      <td>521Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>A001</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>통화-본원통화</td>\n",
              "      <td>102Y002</td>\n",
              "      <td>M</td>\n",
              "      <td>ABA1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>통화-M2</td>\n",
              "      <td>101Y004</td>\n",
              "      <td>M</td>\n",
              "      <td>BBHA00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>금리-기준금리</td>\n",
              "      <td>722Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0101000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>금리-콜(1일)</td>\n",
              "      <td>817Y002</td>\n",
              "      <td>D</td>\n",
              "      <td>010101000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>금리-국고채(3년)</td>\n",
              "      <td>817Y002</td>\n",
              "      <td>D</td>\n",
              "      <td>010200000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>금리-국고채(10년)</td>\n",
              "      <td>817Y002</td>\n",
              "      <td>D</td>\n",
              "      <td>010210000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>대출-예금은행</td>\n",
              "      <td>121Y006</td>\n",
              "      <td>M</td>\n",
              "      <td>BECBLA01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>대출-대기업</td>\n",
              "      <td>121Y006</td>\n",
              "      <td>M</td>\n",
              "      <td>BECBLA0201</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>대출-가계</td>\n",
              "      <td>121Y006</td>\n",
              "      <td>M</td>\n",
              "      <td>BECBLA03</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>대출-주담대</td>\n",
              "      <td>121Y006</td>\n",
              "      <td>M</td>\n",
              "      <td>BECBLA0302</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>주식시장-KOSPI지수</td>\n",
              "      <td>802Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0001000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>주식시장-거래량</td>\n",
              "      <td>802Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0002000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>주식시장-거래대금</td>\n",
              "      <td>802Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0003000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>주식시장-외국인순매수</td>\n",
              "      <td>802Y001</td>\n",
              "      <td>D</td>\n",
              "      <td>0030000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>재정-총수입</td>\n",
              "      <td>901Y013</td>\n",
              "      <td>M</td>\n",
              "      <td>A01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>재정-소득세</td>\n",
              "      <td>901Y013</td>\n",
              "      <td>M</td>\n",
              "      <td>A010101</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>재정-재화/용역세</td>\n",
              "      <td>901Y013</td>\n",
              "      <td>M</td>\n",
              "      <td>A010103</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>재정-관세</td>\n",
              "      <td>901Y013</td>\n",
              "      <td>M</td>\n",
              "      <td>A010104</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>재정-총지출</td>\n",
              "      <td>901Y013</td>\n",
              "      <td>M</td>\n",
              "      <td>B01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>재정-보조금</td>\n",
              "      <td>901Y013</td>\n",
              "      <td>M</td>\n",
              "      <td>B0101031</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>재정-경상지출</td>\n",
              "      <td>901Y013</td>\n",
              "      <td>M</td>\n",
              "      <td>B010101</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>국민소득-GDP</td>\n",
              "      <td>200Y005</td>\n",
              "      <td>Q</td>\n",
              "      <td>1400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>국민소득-GNI</td>\n",
              "      <td>200Y006</td>\n",
              "      <td>Q</td>\n",
              "      <td>1600</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>국제금리-미국6개월</td>\n",
              "      <td>902Y001</td>\n",
              "      <td>M</td>\n",
              "      <td>1020302</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>국제금리-미국5년</td>\n",
              "      <td>902Y001</td>\n",
              "      <td>M</td>\n",
              "      <td>1020402</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>국제금리-미국10년</td>\n",
              "      <td>902Y001</td>\n",
              "      <td>M</td>\n",
              "      <td>1020403</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>국제주가지수-다우존스</td>\n",
              "      <td>902Y002</td>\n",
              "      <td>M</td>\n",
              "      <td>3020101</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>국제주가지수-나스닥</td>\n",
              "      <td>902Y002</td>\n",
              "      <td>M</td>\n",
              "      <td>3020103</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>국제주가지수-니케이</td>\n",
              "      <td>902Y002</td>\n",
              "      <td>M</td>\n",
              "      <td>3020108</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>국제주가지수-항셍</td>\n",
              "      <td>902Y002</td>\n",
              "      <td>M</td>\n",
              "      <td>3020114</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>국제주가지수-중국</td>\n",
              "      <td>902Y002</td>\n",
              "      <td>M</td>\n",
              "      <td>3020115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>국제주가지수-독일</td>\n",
              "      <td>902Y002</td>\n",
              "      <td>M</td>\n",
              "      <td>3020106</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>노동-고용률</td>\n",
              "      <td>901Y027</td>\n",
              "      <td>M</td>\n",
              "      <td>I61E</td>\n",
              "      <td>I28A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>노동-경제활동참가율</td>\n",
              "      <td>901Y027</td>\n",
              "      <td>M</td>\n",
              "      <td>I61D</td>\n",
              "      <td>I28A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>노동-실업률</td>\n",
              "      <td>902Y021</td>\n",
              "      <td>M</td>\n",
              "      <td>KOR</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>노동-미국실업률</td>\n",
              "      <td>902Y021</td>\n",
              "      <td>M</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>금리-미국금리</td>\n",
              "      <td>902Y001</td>\n",
              "      <td>M</td>\n",
              "      <td>1020302</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cc0a3a5-41c2-4684-b99c-366e600a4128')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cc0a3a5-41c2-4684-b99c-366e600a4128 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cc0a3a5-41c2-4684-b99c-366e600a4128');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "pd.read_csv(\"/content/ECOSindex.csv\") #조사할 지표와와 호출부호"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UPT54qjebEm"
      },
      "outputs": [],
      "source": [
        "#세부 통계 데이터 조회\n",
        "#url = \"http://ecos.bok.or.kr/api/StatisticSearch(세부통계조회)/sample(인증키)/json(데이터 표시 형식)\n",
        "#/kr(언어)/1(시작번호)/10(끝번호)/200Y001(통계표코드)/A(주기:A/S/Q/SM/D)/2015(검색시작일자)/2021(검색종료일자)\n",
        "#/10101(통계항목1코드)/1010101(통계항목2코드)/10102(통계항목3코드)/?(통계항목4코드)\"\n",
        "\n",
        "\n",
        "## 한국은행 API url 주소 함수##\n",
        "def ecos_url(startnum=None,endnum=None,statcode=None,cycle=None,startdate=None,enddate=None,msc1=None,msc2=None,msc3=None,msc4=None):\n",
        "    url = \"http://ecos.bok.or.kr/api/StatisticSearch/R0FQKORGKXRKG6CIJS2V/json/kr\" \n",
        "    if not startnum is None : url = url + \"/\" + str(startnum)\n",
        "    if not endnum is None : url = url + \"/\" + str(endnum)\n",
        "    if not statcode is None : url = url + \"/\" + str(statcode)\n",
        "    if not cycle is None : url = url + \"/\" + str(cycle)\n",
        "    if not startdate is None: url = url + \"/\" + str(startdate)\n",
        "    if not enddate is None: url = url + \"/\" + str(enddate)\n",
        "    if not msc1 is None : url = url + \"/\" + str(msc1)\n",
        "    if not msc2 is None : url = url + \"/\" + str(msc2)\n",
        "    if not msc3 is None : url = url + \"/\" + str(msc3)\n",
        "    if not msc4 is None : url = url + \"/\" + str(msc4)\n",
        "    return url\n",
        "\n",
        "#Test용 URL\n",
        "url = ecos_url(1,10,\"722Y004\",\"M\",\"202107\",\"202205\",\"101000\")\n",
        "#ecos_stat(url)\n",
        "\n",
        "\n",
        "#데이터 조회함수\n",
        "def ecos_stat(url):\n",
        "    resp = requests.get(url)\n",
        "    print(resp.status_code) #API 서버 메세지\n",
        "    data = resp.json()\n",
        "    sdata = data['StatisticSearch']['row']\n",
        "    ecos_df = pd.DataFrame(sdata)\n",
        "    a = ecos_df['ITEM_NAME1']\n",
        "    a = a[0]\n",
        "    #a = a['ITEM_NAME1'] # 첫번째 행 추출, 데이터프레임 키값 얻는용\n",
        "    prcs_df = ecos_df[['TIME','DATA_VALUE']]\n",
        "    prcs_df.columns = ['TIME',a]\n",
        "    \n",
        "    b = len(prcs_df)\n",
        "\n",
        "    for i in range(0,b):\n",
        "        x = str(prcs_df.loc[i,'TIME'])\n",
        "        c = x[4] \n",
        "        d = x[5] \n",
        "        e = x[0:4] \n",
        "        if c == \"Q\" : \n",
        "            if d == \"1\" : prcs_df.loc[i,'TIME'] = e +\"0331\"\n",
        "            if d == \"2\" : prcs_df.loc[i,'TIME'] = e +\"0630\"\n",
        "            if d == \"3\" : prcs_df.loc[i,'TIME'] = e +\"0930\"\n",
        "            if d == \"4\" : prcs_df.loc[i,'TIME'] = e +\"1231\"\n",
        "\n",
        "        if len(prcs_df.loc[i,'TIME']) == 6 : prcs_df.loc[i,'TIME'] = x + \"01\"\n",
        "    return prcs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-KuK0OKb0lZX",
        "outputId": "59da8fd9-8d4b-464e-f8e3-9502e9e8bd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "1번째 쿼리 완료..!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:723: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "2번째 쿼리 완료..!\n",
            "200\n",
            "3번째 쿼리 완료..!\n",
            "200\n",
            "4번째 쿼리 완료..!\n",
            "200\n",
            "5번째 쿼리 완료..!\n",
            "200\n",
            "6번째 쿼리 완료..!\n",
            "200\n",
            "7번째 쿼리 완료..!\n",
            "200\n",
            "8번째 쿼리 완료..!\n",
            "200\n",
            "9번째 쿼리 완료..!\n",
            "200\n",
            "10번째 쿼리 완료..!\n",
            "200\n",
            "11번째 쿼리 완료..!\n",
            "200\n",
            "12번째 쿼리 완료..!\n",
            "200\n",
            "13번째 쿼리 완료..!\n",
            "200\n",
            "14번째 쿼리 완료..!\n",
            "200\n",
            "15번째 쿼리 완료..!\n",
            "200\n",
            "16번째 쿼리 완료..!\n",
            "200\n",
            "17번째 쿼리 완료..!\n",
            "200\n",
            "18번째 쿼리 완료..!\n",
            "200\n",
            "19번째 쿼리 완료..!\n",
            "200\n",
            "20번째 쿼리 완료..!\n",
            "200\n",
            "21번째 쿼리 완료..!\n",
            "200\n",
            "22번째 쿼리 완료..!\n",
            "200\n",
            "23번째 쿼리 완료..!\n",
            "200\n",
            "24번째 쿼리 완료..!\n",
            "200\n",
            "25번째 쿼리 완료..!\n",
            "200\n",
            "26번째 쿼리 완료..!\n",
            "200\n",
            "27번째 쿼리 완료..!\n",
            "200\n",
            "28번째 쿼리 완료..!\n",
            "200\n",
            "29번째 쿼리 완료..!\n",
            "200\n",
            "30번째 쿼리 완료..!\n",
            "200\n",
            "31번째 쿼리 완료..!\n",
            "200\n",
            "32번째 쿼리 완료..!\n",
            "200\n",
            "33번째 쿼리 완료..!\n",
            "200\n",
            "34번째 쿼리 완료..!\n",
            "200\n",
            "35번째 쿼리 완료..!\n",
            "200\n",
            "36번째 쿼리 완료..!\n",
            "200\n",
            "37번째 쿼리 완료..!\n",
            "200\n",
            "38번째 쿼리 완료..!\n",
            "200\n",
            "39번째 쿼리 완료..!\n",
            "200\n",
            "40번째 쿼리 완료..!\n",
            "200\n",
            "41번째 쿼리 완료..!\n",
            "200\n",
            "42번째 쿼리 완료..!\n",
            "200\n",
            "43번째 쿼리 완료..!\n",
            "200\n",
            "44번째 쿼리 완료..!\n",
            "200\n",
            "45번째 쿼리 완료..!\n",
            "200\n",
            "46번째 쿼리 완료..!\n",
            "200\n",
            "47번째 쿼리 완료..!\n",
            "200\n",
            "48번째 쿼리 완료..!\n",
            "200\n",
            "49번째 쿼리 완료..!\n",
            "200\n",
            "50번째 쿼리 완료..!\n",
            "200\n",
            "51번째 쿼리 완료..!\n",
            "200\n",
            "52번째 쿼리 완료..!\n",
            "200\n",
            "53번째 쿼리 완료..!\n",
            "200\n",
            "54번째 쿼리 완료..!\n",
            "200\n",
            "55번째 쿼리 완료..!\n",
            "200\n",
            "56번째 쿼리 완료..!\n",
            "200\n",
            "57번째 쿼리 완료..!\n",
            "200\n",
            "58번째 쿼리 완료..!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          TIME    no 국내총생산(GDP)(실질, 계절조정, 전기비) 비농림어업GDP  농림어업   제조업   건설업  \\\n",
              "0     20150701     0                       1.4      1.4   4.7   0.8   5.2   \n",
              "1     20150702     1                       1.4      1.4   4.7   0.8   5.2   \n",
              "2     20150703     2                       1.4      1.4   4.7   0.8   5.2   \n",
              "3     20150704     3                       1.4      1.4   4.7   0.8   5.2   \n",
              "4     20150705     4                       1.4      1.4   4.7   0.8   5.2   \n",
              "...        ...   ...                       ...      ...   ...   ...   ...   \n",
              "2553  20220627  2553                       0.6      0.6   1.6   3.3  -1.6   \n",
              "2554  20220628  2554                       0.6      0.6   1.6   3.3  -1.6   \n",
              "2555  20220629  2555                       0.6      0.6   1.6   3.3  -1.6   \n",
              "2556  20220630  2556                       0.7      0.9  -6.4  -1.1   0.2   \n",
              "2557  20220701  2557                       0.7      0.9  -6.4  -1.1   0.2   \n",
              "\n",
              "     서비스업 ICT산업 비ICT산업  ... 미국(NASDAQ) 일본(NIKKEI)    홍콩(항셍) 중국(SHCOMP)  \\\n",
              "0     1.2   0.9    1.5  ...    5128.28   20585.24  24636.28    3663.73   \n",
              "1     1.2   0.9    1.5  ...    5128.28   20585.24  24636.28    3663.73   \n",
              "2     1.2   0.9    1.5  ...    5128.28   20585.24  24636.28    3663.73   \n",
              "3     1.2   0.9    1.5  ...    5128.28   20585.24  24636.28    3663.73   \n",
              "4     1.2   0.9    1.5  ...    5128.28   20585.24  24636.28    3663.73   \n",
              "...   ...   ...    ...  ...        ...        ...       ...        ...   \n",
              "2553    0   0.5      1  ...   11028.74   26393.04  21859.79    3398.62   \n",
              "2554    0   0.5      1  ...   11028.74   26393.04  21859.79    3398.62   \n",
              "2555    0   0.5      1  ...   11028.74   26393.04  21859.79    3398.62   \n",
              "2556  1.8   0.5      1  ...   11028.74   26393.04  21859.79    3398.62   \n",
              "2557  1.8   0.5      1  ...   11028.74   26393.04  21859.79    3398.62   \n",
              "\n",
              "       독일(DAX)   고용률 경제활동참가율   한국   미국 T/Bill(6M)_y  \n",
              "0     11308.99  61.3    63.6  3.7  5.2        0.142  \n",
              "1     11308.99  61.3    63.6  3.7  5.2        0.142  \n",
              "2     11308.99  61.3    63.6  3.7  5.2        0.142  \n",
              "3     11308.99  61.3    63.6  3.7  5.2        0.142  \n",
              "4     11308.99  61.3    63.6  3.7  5.2        0.142  \n",
              "...        ...   ...     ...  ...  ...          ...  \n",
              "2553  12783.77  62.9    64.9  2.9  3.6        2.458  \n",
              "2554  12783.77  62.9    64.9  2.9  3.6        2.458  \n",
              "2555  12783.77  62.9    64.9  2.9  3.6        2.458  \n",
              "2556  12783.77  62.9    64.9  2.9  3.6        2.458  \n",
              "2557  12783.77  62.9    64.9  2.9  3.6        2.458  \n",
              "\n",
              "[2558 rows x 60 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdc450dc-0c76-446e-a006-cd9cd8d3c0bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIME</th>\n",
              "      <th>no</th>\n",
              "      <th>국내총생산(GDP)(실질, 계절조정, 전기비)</th>\n",
              "      <th>비농림어업GDP</th>\n",
              "      <th>농림어업</th>\n",
              "      <th>제조업</th>\n",
              "      <th>건설업</th>\n",
              "      <th>서비스업</th>\n",
              "      <th>ICT산업</th>\n",
              "      <th>비ICT산업</th>\n",
              "      <th>...</th>\n",
              "      <th>미국(NASDAQ)</th>\n",
              "      <th>일본(NIKKEI)</th>\n",
              "      <th>홍콩(항셍)</th>\n",
              "      <th>중국(SHCOMP)</th>\n",
              "      <th>독일(DAX)</th>\n",
              "      <th>고용률</th>\n",
              "      <th>경제활동참가율</th>\n",
              "      <th>한국</th>\n",
              "      <th>미국</th>\n",
              "      <th>T/Bill(6M)_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20150701</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>...</td>\n",
              "      <td>5128.28</td>\n",
              "      <td>20585.24</td>\n",
              "      <td>24636.28</td>\n",
              "      <td>3663.73</td>\n",
              "      <td>11308.99</td>\n",
              "      <td>61.3</td>\n",
              "      <td>63.6</td>\n",
              "      <td>3.7</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20150702</td>\n",
              "      <td>1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>...</td>\n",
              "      <td>5128.28</td>\n",
              "      <td>20585.24</td>\n",
              "      <td>24636.28</td>\n",
              "      <td>3663.73</td>\n",
              "      <td>11308.99</td>\n",
              "      <td>61.3</td>\n",
              "      <td>63.6</td>\n",
              "      <td>3.7</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20150703</td>\n",
              "      <td>2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>...</td>\n",
              "      <td>5128.28</td>\n",
              "      <td>20585.24</td>\n",
              "      <td>24636.28</td>\n",
              "      <td>3663.73</td>\n",
              "      <td>11308.99</td>\n",
              "      <td>61.3</td>\n",
              "      <td>63.6</td>\n",
              "      <td>3.7</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20150704</td>\n",
              "      <td>3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>...</td>\n",
              "      <td>5128.28</td>\n",
              "      <td>20585.24</td>\n",
              "      <td>24636.28</td>\n",
              "      <td>3663.73</td>\n",
              "      <td>11308.99</td>\n",
              "      <td>61.3</td>\n",
              "      <td>63.6</td>\n",
              "      <td>3.7</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20150705</td>\n",
              "      <td>4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>...</td>\n",
              "      <td>5128.28</td>\n",
              "      <td>20585.24</td>\n",
              "      <td>24636.28</td>\n",
              "      <td>3663.73</td>\n",
              "      <td>11308.99</td>\n",
              "      <td>61.3</td>\n",
              "      <td>63.6</td>\n",
              "      <td>3.7</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2553</th>\n",
              "      <td>20220627</td>\n",
              "      <td>2553</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.6</td>\n",
              "      <td>3.3</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>11028.74</td>\n",
              "      <td>26393.04</td>\n",
              "      <td>21859.79</td>\n",
              "      <td>3398.62</td>\n",
              "      <td>12783.77</td>\n",
              "      <td>62.9</td>\n",
              "      <td>64.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2554</th>\n",
              "      <td>20220628</td>\n",
              "      <td>2554</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.6</td>\n",
              "      <td>3.3</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>11028.74</td>\n",
              "      <td>26393.04</td>\n",
              "      <td>21859.79</td>\n",
              "      <td>3398.62</td>\n",
              "      <td>12783.77</td>\n",
              "      <td>62.9</td>\n",
              "      <td>64.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2555</th>\n",
              "      <td>20220629</td>\n",
              "      <td>2555</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.6</td>\n",
              "      <td>3.3</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>11028.74</td>\n",
              "      <td>26393.04</td>\n",
              "      <td>21859.79</td>\n",
              "      <td>3398.62</td>\n",
              "      <td>12783.77</td>\n",
              "      <td>62.9</td>\n",
              "      <td>64.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2556</th>\n",
              "      <td>20220630</td>\n",
              "      <td>2556</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>-6.4</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>11028.74</td>\n",
              "      <td>26393.04</td>\n",
              "      <td>21859.79</td>\n",
              "      <td>3398.62</td>\n",
              "      <td>12783.77</td>\n",
              "      <td>62.9</td>\n",
              "      <td>64.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2557</th>\n",
              "      <td>20220701</td>\n",
              "      <td>2557</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>-6.4</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>11028.74</td>\n",
              "      <td>26393.04</td>\n",
              "      <td>21859.79</td>\n",
              "      <td>3398.62</td>\n",
              "      <td>12783.77</td>\n",
              "      <td>62.9</td>\n",
              "      <td>64.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2558 rows × 60 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdc450dc-0c76-446e-a006-cd9cd8d3c0bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdc450dc-0c76-446e-a006-cd9cd8d3c0bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdc450dc-0c76-446e-a006-cd9cd8d3c0bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "\n",
        "csv = pd.read_csv('/content/ECOSindex.csv') #주의, 엑셀로 한 번 연 뒤 업로드시 코드 내 '0' 사라짐, 디스코드 내 파일 사용\n",
        "\n",
        "startdate = str(20150701) #API 요청인자(시작일)\n",
        "enddate = str(20220701) #API 요청인자(종료일)\n",
        "startnum = 1 #API 요청인자(요청건수-시작)\n",
        "\n",
        "dt_startdate = datetime.datetime(int(startdate[0:4]),int(startdate[4:6]),int(startdate[6:8]))\n",
        "dt_enddate = datetime.datetime(int(enddate[0:4]),int(enddate[4:6]),int(enddate[6:8]))\n",
        "datediff = dt_enddate-dt_startdate\n",
        "endnum = datediff.days -1 #API 요청인자(요청건수-마지막)\n",
        "\n",
        "#daterange :날짜 스트링 -> Datetime 형식으로 변환 \n",
        "drange = pd.date_range(datetime.datetime.strptime(startdate, \"%Y%m%d\"),datetime.datetime.strptime(enddate,\"%Y%m%d\"))\n",
        "drange = drange.strftime(\"%Y%m%d\")\n",
        "#number of range\n",
        "norange = range(0,len(drange))\n",
        "ecos_df2 = pd.DataFrame({\n",
        "        'TIME': drange,\n",
        "        'no' : norange\n",
        "    })\n",
        "\n",
        "#csv파일에 잘못된 코드분류가가 있는듯 -> 해결\n",
        "# 30분 내 300건 호출제한, (너무 많이 했음)\n",
        "\n",
        "#csv 파일에 게재된 종목의 수 만큼 호출\n",
        "for i in range(0,len(csv)) : \n",
        "    csv_sliced = [csv.loc[i,'코드명'],csv.loc[i,'사이클'],startdate,enddate,str(csv.loc[i,'코드1']),str(csv.loc[i,'코드2'])]\n",
        "    # API 쿼리용 날짜 수정\n",
        "    st_quarter = int(int(csv_sliced[2][4:6])/3)+1\n",
        "    en_quarter = int(int(csv_sliced[3][4:6])/3)+1\n",
        "\n",
        "    if csv_sliced[1] == \"Q\" : \n",
        "        csv_sliced[2] = csv_sliced[2][0:4] + \"Q\" + str(st_quarter)\n",
        "        csv_sliced[3] = csv_sliced[3][0:4] + \"Q\" + str(en_quarter)\n",
        "    if csv_sliced[1] == \"M\" : \n",
        "        csv_sliced[2] = csv_sliced[2][0:6]\n",
        "        csv_sliced[3] = csv_sliced[3][0:6]\n",
        "\n",
        "    query = ecos_url(startnum,endnum,csv_sliced[0],csv_sliced[1],csv_sliced[2],csv_sliced[3],csv_sliced[4],csv_sliced[5])\n",
        "    #print(query)\n",
        "    ecos_df1 = ecos_stat(query)\n",
        "    ecos_df2 = pd.merge(ecos_df2, ecos_df1, how='outer',on='TIME')\n",
        "    print(str(i+1) + \"번째 쿼리 완료..!\")\n",
        "\n",
        "# 실질 경제변수가 발생한 기간상으로는 bfill -> ffill 이 맞는데,\n",
        "# 지표 발표후 지표가 주가 변동에 대해 미치는 독립변수적인 영향을 고려하면 ffill -> bfill이 맞음\n",
        "ecos_df2 = ecos_df2.fillna(method='ffill')\n",
        "ecos_df2 = ecos_df2.fillna(method='bfill')\n",
        "ecos_df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXlqK-j23kUO"
      },
      "source": [
        "# **2. KOSPI 인덱스 API 크롤링 (출처: NAVER Finance) (KOSPI index Crawling)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRzFq13IRJT3"
      },
      "source": [
        "수집할 NAVER Finance 주소: https://finance.naver.com/sise/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmssImpiRZ3B"
      },
      "source": [
        "(1) 수집할 ticker의 code와 name을 설정\n",
        "\n",
        "(2) 수집할 주소의 링크를 url2 에 저장\n",
        "\n",
        "(3) 주소에 user-agent로 접근해 html을 가져온뒤, dataframe으로 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlJPGEpADVZG"
      },
      "outputs": [],
      "source": [
        "ticker_code = \"226490\"                                                          #request를 위한 변수: ticker_code       #KODEX 코스피 ETF\n",
        "ticker_name = \"KODEX 코스피\"                                                    #request 할 변수의 실제 이름(종목)\n",
        "page_no = 1                                                                     #불러올 page의 number\n",
        "url2 = \"https://finance.naver.com/item/sise_day.nhn?code={}&page={}\"            #formating : {}에 변수 이름을 지정, url2에 문자열(수집할 주소)을 저장.\n",
        "url2 = url2.format(ticker_code, page_no)                                        #url2에 formatting된 문자열(수집할 주소)을 저장.\n",
        "\n",
        "#user-agent: 크롤링시 request 함수를 사용하는 대신, user가 직접 주소에서 HTTP를 요청하는 것으로 위장.\n",
        "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.53 Safari/537.36 Edg/103.0.1264.37'}\n",
        "response2 = requests.get(url2, headers=headers)\n",
        "\n",
        "from bs4 import BeautifulSoup as bs                                             #BeautifulSoup 불러오기 (html내의 정보를 가져오기 위해 사용)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpmox3MKGl_j"
      },
      "outputs": [],
      "source": [
        "# 종목 번호를 이용해 page에 따라 데이터를 읽어오는 함수\n",
        "# \"\"\" 는 이 두개 사이의 행들은 주석 처리되며, 함수의 docstring 으로 사용됩니다.\n",
        "\n",
        "def get_day_list(ticker_code, page_no):\n",
        "    \"\"\"\n",
        "    일자별 시세를 페이지별로 수집\n",
        "    \"\"\" \n",
        "    url2 = f\"https://finance.naver.com/item/sise_day.nhn?code={ticker_code}&page={page_no}\"\n",
        "    \n",
        "    headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.53 Safari/537.36 Edg/103.0.1264.37'}\n",
        "\n",
        "    response2 = requests.get(url2, headers=headers)\n",
        "    html = bs(response2.text, \"lxml\")\n",
        "    table = html.select(\"table\")\n",
        "    table = pd.read_html(str(table))\n",
        "    temp_df = table[0].dropna()\n",
        "    return temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XFeuuwZZHR0K",
        "outputId": "9b1e2d29-87f2-48de-f81c-0770e2e250ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c912cc19f7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'날짜'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mindex1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2015.08.24\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2022.07.01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex1\u001b[0m\u001b[0;34m)\u001b[0m                                                         \u001b[0;31m#시계열 데이터의 index를 index1으로 재설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m#만약 df1.reindex(index1, method='ffill') 이면                                  #forward-propagation    결측값 채우기  ffill: 앞의 값으로, bfill: 뒤의 값으로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                                                 \u001b[0;31m#코스피 지수는 안됨. 월별, 분기별 데이터에 적용?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4771\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4772\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4774\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4817\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4818\u001b[0m         return self._reindex_axes(\n\u001b[0;32m-> 4819\u001b[0;31m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4820\u001b[0m         ).__finalize__(self, method=\"reindex\")\n\u001b[1;32m   4821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4596\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4597\u001b[0m             frame = frame._reindex_index(\n\u001b[0;32m-> 4598\u001b[0;31m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4599\u001b[0m             )\n\u001b[1;32m   4600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[0;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   4618\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4619\u001b[0m             \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4620\u001b[0;31m             \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4621\u001b[0m         )\n\u001b[1;32m   4622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4887\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4888\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4889\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4890\u001b[0m             )\n\u001b[1;32m   4891\u001b[0m             \u001b[0;31m# If we've made a copy once, no need to make another one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3785\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m     def reindex(\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# web page 시작번호\n",
        "page_no = 1\n",
        "# 데이터를 저장할 빈 변수 선언\n",
        "item_list = []\n",
        "\n",
        "while True:\n",
        "    print(page_no)\n",
        "    temp = get_day_list(ticker_code, page_no)\n",
        "    item_list.append(temp)\n",
        "    \n",
        "    page_no = page_no + 1\n",
        "    time.sleep(0.1)\n",
        "    \n",
        "    if page_no > 175:                                                           # 171번째 페이지이면 break\n",
        "        break;\n",
        "df1 = pd.concat(item_list)                                                      #pd.concat : 데이터 속성 형태가 동일한 데이터 셋을 합친다. item_list: row == 10인 dataframe\n",
        "#pd.set_option('display.max_row', 500)                                          #표시할 row, column의 수 설정\n",
        "#pd.set_option('display.max_columns', 100)\n",
        "df1.columns                                                                     #날짜, 종가, 전일비, 시가, 고가, 저가, 거래량\n",
        "df1=df1[['날짜', '종가', '시가', '고가', '거래량']]                             #column을 날짜, 종가, 시가, 고가 거래량으로 한다.\n",
        "df1['datetime']=df1['날짜']\n",
        "df1.set_index('datetime', inplace=True)                                         #인덱스 초기화 drop: 기존인덱스를 버린다. inplace: ???\n",
        "\n",
        "df1.index = pd.to_datetime(df1.index)\n",
        "df1=df1.drop(['날짜'], axis=1)\n",
        "index1=pd.date_range(\"2015.08.24\", \"2022.07.01\")\n",
        "df1=df1.reindex(index1)                                                         #시계열 데이터의 index를 index1으로 재설정 \n",
        "#만약 df1.reindex(index1, method='ffill') 이면                                  #forward-propagation    결측값 채우기  ffill: 앞의 값으로, bfill: 뒤의 값으로\n",
        "                                                                                #코스피 지수는 안됨. 월별, 분기별 데이터에 적용?\n",
        "#단위 : 원\n",
        "df1                                                                             ##row=266"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfCkeqipTPmh"
      },
      "source": [
        "#  **3. 데이터 취합 (Data Gathering)** \n",
        "<br>\n",
        "< result 변수 사용하다 보니 순서를 좀 바꿨어요;ㅎ - 동환 >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPgcjJYGTZf2"
      },
      "outputs": [],
      "source": [
        "ecos_df2['datetime']=ecos_df2['TIME']\n",
        "ecos_df2.set_index('datetime', inplace=True)                                        \n",
        "\n",
        "ecos_df2.index = pd.to_datetime(ecos_df2.index)\n",
        "ecos_df2=ecos_df2.drop(['TIME', 'no'], axis=1)\n",
        "ecos_df2 = ecos_df2.reindex(index1)\n",
        "\n",
        "from google.colab.data_table import DataTable                                   #63 column까지 보기 위해 사용\n",
        "DataTable.max_columns = 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCasjC6AYHqg"
      },
      "outputs": [],
      "source": [
        "result= (pd.concat([df1, ecos_df2], axis= 1)).dropna()\n",
        "result                                                                          #전체 데이터중 코스피 휴장일 drop한 데이터, idx = datetime\n",
        "#KODEX 코스피 ETF : 종가 시가 고가: 원, 거래량: (1주)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzxJ0zExQ-0a"
      },
      "source": [
        " # **4. GJR-GARCH(p,q) Model Adding** <br>\n",
        " [t-k,t]기간 동안의 변동성을 고려한 [t+1]기의 주가변동성 산출모델 <br>\n",
        " 위의 result 변수 사용중\n",
        "\n",
        "<font color=\"yellow\"> est_vol -> 코스피 t+1기 변동성 예측치</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8stEThufRvy1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "#print(result.index) # 휴장일 drop 된 날씨\n",
        "#print(result.columns)\n",
        "\n",
        "kospi_index =  result['KOSPI지수'] #코스피 지수 칼럼 추출\n",
        "\n",
        "\n",
        "#칼럼 행 갯수에 맞는 어레이 선언\n",
        "\n",
        " \n",
        "null_array = np.array([0] * len(kospi_index),float)\n",
        "kospi_pctchange = null_array\n",
        "\n",
        "\n",
        "for i in range(1,len(kospi_index)) : #일일 변동치 4자리 퍼센티지로 표시\n",
        "    kospi_pctchange[i] = (float(kospi_index[i]) - float(kospi_index[i-1]))/float(kospi_index[i-1]) *100\n",
        "    kospi_pctchange[i] = float(round(kospi_pctchange[i],5))\n",
        "\n",
        "kospi_pctchange[0] = 0\n",
        "\n",
        "kospi_pctchange = pd.DataFrame(kospi_pctchange,index= result.index)\n",
        "kospi_pctchange.columns = ['퍼센트변화율']\n",
        "\n",
        "kospi_index = pd.merge(kospi_index,kospi_pctchange, how='inner',on=kospi_index.index)\n",
        "\n",
        "kospi_index.columns = ['DATE','KOSPI지수',\"퍼센트변화율\"]\n",
        "kospi_index.set_index('DATE',inplace=True)\n",
        "#print(sum(kospi_pctchange)/len(kospi_pctchange))\n",
        "#print(kospi_pctchange.mean())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLlPOCjBABv9"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "!pip install arch\n",
        "from arch import arch_model\n",
        "import inspect\n",
        "\n",
        "#arch.univariate.arch_model(y, x=None, mean='Constant', lags=0, vol='Garch',\n",
        "# p=1, o=0, q=1, power=2.0, dist='Normal', hold_back=None, rescale=None)\n",
        "#aa = arch.univariate.arch_model(kospi_pctchange['퍼센트변화율'],vol='Garch',p=1,o=1,q=1,)\n",
        "\n",
        "am = arch_model(kospi_pctchange['퍼센트변화율'], p=1, o=1, q=1)\n",
        "res = am.fit(update_freq=5, disp=\"off\")\n",
        "#print(res.summary())\n",
        "\n",
        "tableau = pd.DataFrame(res.summary().tables[2])\n",
        "\n",
        "#GJR-garch 적합값\n",
        "\n",
        "\n",
        "omega = float(str(tableau.iloc[1,1]))\n",
        "alpha = float(str(tableau.iloc[2,1]))\n",
        "gamma = float(str(tableau.iloc[3,1]))\n",
        "beta = float(str(tableau.iloc[4,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd8bCCd6pIq3"
      },
      "outputs": [],
      "source": [
        "est_vol = pd.DataFrame(np.zeros((len(kospi_pctchange['퍼센트변화율']), 1)))\n",
        "est_vol.iloc[0,0] = kospi_pctchange.var() #; print(est_vol)\n",
        "kospi_pctchange1 = kospi_pctchange\n",
        "kospi_pctchange1 = kospi_pctchange.reset_index()\n",
        "kospi_pctchange1 = kospi_pctchange1['퍼센트변화율']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQvv6TnSrP33"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "for i in range(1,len(kospi_pctchange1)) :\n",
        "    err_term_sqrt = kospi_pctchange1.iloc[i-1]/math.sqrt(est_vol.iloc[i-1])\n",
        "    \n",
        "    err_term_squared = pow(err_term_sqrt,2)\n",
        "    if err_term_sqrt < 0 :\n",
        "        est_vol.iloc[i] = omega + alpha * err_term_squared + beta * est_vol.iloc[i-1,0]\n",
        "    else :\n",
        "        est_vol.iloc[i] = omega + (alpha * err_term_squared) + (gamma * err_term_squared) + (beta * est_vol.iloc[i-1])\n",
        "\n",
        "print(est_vol) # GJR-GARCH(1,1) 변동성\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDmYATQ04NIl"
      },
      "outputs": [],
      "source": [
        "est_vol.set_index(result.index)\n",
        "est_vol.columns = [\"est_vol\"]\n",
        "est_vol = est_vol.set_index(result.index)\n",
        "est_vol.index_name = 'DATE'\n",
        "est_vol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC8sYVgV6HRh"
      },
      "source": [
        "#  **5. 데이터 정규화 및 최종 취합 (Final Data Gathering & Normalization for ML)**\n",
        "\n",
        "<font color='yellow'>\n",
        "raw_data_final <- result파일 + GARCH모형 변동성 추가본\n",
        "\n",
        "raw_data_scaled <- 위 데이터 정규화 파일 [0~1]\n",
        "</font> \n",
        "\n",
        "<font color='grey'>\n",
        "채택 데이터\n",
        "</font> <br>\n",
        "\n",
        "<font color='grey'>\n",
        "<실물시장변수>\n",
        "GDP-총액(4), \n",
        "노동-실업률(59)\n",
        "재정-총지출(43)\n",
        "<\n",
        "<font color='grey'>\n",
        "물가-CPI(18), \n",
        "노동-미국실업률(57)\n",
        "</font> <br>\n",
        "\n",
        "<font color='grey'>\n",
        "<화폐시장변수>\n",
        "통화-M2(23), \n",
        "금리-기준금리(25)\n",
        "금리-미국기준금리(61) \n",
        "</font> <br>\n",
        "\n",
        "<font color='grey'>\n",
        "<자본시장변수>\n",
        "환율-USD(14), \n",
        "국제주가지수- 나스닥(49)\n",
        "국제주가지수- 항셍(51)\n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EvHvCEf_KzY"
      },
      "outputs": [],
      "source": [
        "raw_data_final = result.iloc[:,[4,27,43,17,21,59,60,28,61,35,52,54]] ; raw_data_final.set_index(result.index)\n",
        "raw_data_final = raw_data_final.astype(float)\n",
        "data_modified = raw_data_final.iloc[:,1]\n",
        "\n",
        "#변동성 지표 추가\n",
        "raw_data_final = raw_data_final.join(est_vol)\n",
        "#한/미 기준금리 삭제, 금리차 데이터 대체\n",
        "interest_disparity = raw_data_final['콜금리(1일, 전체거래)'] - raw_data_final['T/Bill(6M)_y']\n",
        "interest_disparity = pd.DataFrame({'금리차' : interest_disparity})\n",
        "raw_data_final = raw_data_final.join(interest_disparity)\n",
        "raw_data_final = raw_data_final.drop(['콜금리(1일, 전체거래)','T/Bill(6M)_y'],axis=1)\n",
        "\n",
        "\n",
        "raw_data_final = raw_data_final.set_axis(['GDP','M2','Gov_Exp', 'KRW/USD', 'CPI', 'UnEmp(KR)','UnEmp(US)','KOSPI','NASDAQ','HANGSENG','Est_Vol','Interest Gap'], axis=1, inplace=False)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler_ = MinMaxScaler()\n",
        "scaler_.fit(raw_data_final)\n",
        "rawdata_scaled_ = scaler_.transform(raw_data_final)\n",
        "\n",
        "raw_data_scaled = pd.DataFrame(rawdata_scaled_, columns=raw_data_final.columns)\n",
        "\n",
        "#raw_data_scaled # 정규화 [0~1]\n",
        "\n",
        "raw_data_scaled \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiAQM4xt6AAK"
      },
      "source": [
        "#**6. 데이터(KOSPI, 경제지표) 상관관계 분석 (Data Correlation Analysis)** </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv1kIBRIHrg6"
      },
      "outputs": [],
      "source": [
        "#many-to-one? 5 days to 1 day\n",
        "\n",
        "\n",
        "# test data : 2021.07.01 ~ 2022.07.01 (영업일은 247일)\n",
        "# train data : 2015.08.24 ~ 2021.06.30                                                                             \n",
        "\n",
        "#model : LSTM (quite accurate)\n",
        "#reference https://diane-space.tistory.com/331"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8kL3HKsfkbI"
      },
      "outputs": [],
      "source": [
        "#checking cross-correlation  \n",
        "import matplotlib.pyplot as plt                                                 # 그래프 확인을 위헤 pyplot을 import\n",
        "from pandas.plotting import lag_plot                                            # 산점도 lag_plot 확인을 위해 import\n",
        "import statsmodels.api as sm\n",
        "#from statsmodels.tsa.arima_model import ARIMA                                  # 주가 예측을 위한 ARIMA 모델 \n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lag_plot(raw_data_scaled ['KOSPI'], lag = 5)  # 지연 : 5                        #KOSPI지수의 day t 와 day t+5의 상관관계\n",
        "plt.title('GDP - Autocorrelation plot with lag = 5')\n",
        "plt.show()\n",
        "# Is there Auto-correlation in data? \n",
        "# reference : https://towardsdatascience.com/time-series-forecasting-predicting-stock-prices-using-an-arima-model-2e3b3080bd70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj7kdtiphZgs"
      },
      "outputs": [],
      "source": [
        "#참고 :보스턴 집값예측 모델\n",
        "#reference : https://datascienceschool.net/03%20machine%20learning/06.04%20%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1%EA%B3%BC%20%EB%B3%80%EC%88%98%20%EC%84%A0%ED%83%9D.html\n",
        "#다중 공선성(multicollineraity) : 독립 변수의 일부가 다른 독립 변수의 조학으로 표현 가능/ 독립변수간 강한 상호 상관 관계\n",
        "#dfy = raw_data_scaled\n",
        "#dfx = \n",
        "import seaborn as sns                                                           #시각화를 위한 seaborn 라이브러리 import\n",
        "\n",
        "corr_matrix = raw_data_scaled.corr()\n",
        "corr_matrix\n",
        "\n",
        "sns.heatmap(corr_matrix,center=0,linewidths=0.8,cmap='Blues',annot=True)\n",
        "plt.gcf().set_size_inches(10,10 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLZiSqFvJ85L"
      },
      "outputs": [],
      "source": [
        "# KOSPI변수와 상관관계가 높은 순서대로 출력\n",
        "corr_order = corr_matrix.corr().loc[: \"Interest Gap\", 'KOSPI'].abs().sort_values(ascending = False)     #abs(): 상관계수 값을 양수로 변경, sort_values(ascending = False): 내림차순\n",
        "corr_order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3usVamqOVh1"
      },
      "outputs": [],
      "source": [
        "# 데이터 분포를 시각화 한다. 상관 관계가 높은 데이터를 추출 \n",
        "# plot_cols2 = ['KOSPI','M2','CPI', 'HANGSENG', 'KRW/USD','UnEmp(US)','NASDAQ','Interest Gap', 'UnEmp(KR)', 'Gov_Exp']  #GDP, Est_Vol은 상관 관계가 낮아 제외\n",
        "\n",
        "# 장기적으로는 NASDAQ과 CPI, M2, Gov_Exp, HANGSENG 과 높은 상관관계\n",
        "plot_cols2 = ['KOSPI','NASDAQ','CPI', 'M2','Gov_Exp', 'HANGSENG','Interest Gap', 'Est_Vol'] \n",
        "plot_df = raw_data_scaled .loc[:, plot_cols2]                                   # loc : 특정 부분 추출\n",
        "plot_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_0MmQYPP8Sr"
      },
      "outputs": [],
      "source": [
        "##regplot으로 KOSPI와의 선형 회귀선(추세선) 표시                                 # 선형회귀선의 위아래로 옅게 표시된 부분은 추세선의 95% 신뢰구간을 나타낸다.\n",
        "plt.figure(figsize=(14,12))                                                     # figure의 size를 가로 14. 세로 12\n",
        "for idx, col in enumerate(plot_cols2[1:]):                                      # enumerate 함수를 사용해 plot_cols2의 두 번째 항목부터 반복                          \n",
        "  ax1=plt.subplot(3, 4, idx+1)                                                  # sub plot 9개를 표시하기 위해 설정\n",
        "  sns.regplot(x=col, y=plot_cols2[0], data=plot_df, ax=ax1)                     # y axis : KOSPI, X axis : col\n",
        "plt.show()\n",
        "\n",
        "#선형회귀 대신 딥러닝을 사용한다. 이 셀은 데이터 확인용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw2ROur4Ux1U"
      },
      "source": [
        "way 1: 전일 데이터 들로 다음날을 예측. 5days to 1day.. ex) LSTM 주가 예측 <br>\n",
        "way 2: 하루하루의 개별적 데이터로 KOSPI 지수 예측. 1day 데이터를 모아서.. ex) \n",
        "\n",
        "목표 : way 1처럼 시계열 LSTM/GRU을 하되 way 2처럼 여러 변수 상관관계를 첨가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6toSvswBxtP"
      },
      "source": [
        "ARIMA: AR, MA와 같은 고전적 통계기반시계열분석법을 사용한다.<br>\n",
        "장점 : 모형 해석이 용이<br><br>\n",
        "RNN, LSTM : 인공신경망<br>\n",
        "단점: 모형 해석이 힘들다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLDoDJcdWBqR"
      },
      "outputs": [],
      "source": [
        "# KOSPI 지수 그래프 2015.08.24 ~2022.07.01\n",
        "plot_df['KOSPI'].plot()                                                "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**7. 데이터 딥러닝 학습 및 성능분석 (Deep learning & Performance Analysis)**"
      ],
      "metadata": {
        "id": "9NVivKsiTGv4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFUpqBYO9xe2"
      },
      "outputs": [],
      "source": [
        "# reference : https://data-analysis-expertise.tistory.com/67 에서 입력데이터의 feature을 9개 또는 10개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_MHiwiJE5uA"
      },
      "outputs": [],
      "source": [
        "# LSTM many-to-one model \n",
        "# 과거 X일 동안의 가격을 사용해 1일 동안의 미래 가격을 예측한다.\n",
        "# 현재 시점으로부터 4일 전까지의 데이터를 입력값으로 (5개 열), feature은 'KOSPI','NASDAQ','CPI', 'M2', 'Gov_Exp', 'HANGSENG' ,'Interest Gap', 'Est_Vol'\n",
        "#                                                                                                                   제외: ''KRW/USD','UnEmp(US)','Interest Gap', 'UnEmp(KR)', 4개\n",
        "# 3 차원 input : \n",
        "#                    samples(data_size) : window size(1)에 따라 슬라이싱 할 때 생기는 데이터의 개수       maybe XXXX lines 계산 필요 (영업일)\n",
        "#                    time steps         : 과거 몇개의 데이터를 보는가                                  maybe 5 days\n",
        "#                    feature            : X의 차원. (X의 변수의 개수)                                  maybe 8  'KOSPI','NASDAQ','CPI', 'M2', 'Gov_Exp', 'HANGSENG' ,'Interest Gap', 'Est_Vol'\n",
        "\n",
        "# KOSPI value y = x1w1 + x2w2 + x3w3 + ... + x9w9\n",
        "# 다중 선형 회귀의 경우 가중치 w 를 구해서 입력값 x 와 곱연산\n",
        "\n",
        "# 다중 회귀 결과를 딥러닝 시킬 수 있을까 \n",
        "# train data에서 정답을 KOSPI 값으로 놓고, 입력 feature n개를 딥러닝 돌리면 된다.\n",
        "# 반복 학습으로 '추정된 KOSPI결과'와 '실제 KOSPI결과'를 비교하면서 딥러닝 Accuracy를 높인다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm78ocmF4qiE"
      },
      "outputs": [],
      "source": [
        "#@markdown ![Image in a code cell]( https://drive.google.com/uc?export=view&id=1TVvqKJDMrjjm-uJr42gqkYdhomjtRJWs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x4r4_aVLR5H"
      },
      "outputs": [],
      "source": [
        "# 입력 데이터 재구성\n",
        "def third_dimensionize(all_data, time_steps, for_periods,j):\n",
        "    \"\"\"\n",
        "    목적: \n",
        "            1. 딥러닝용 입력 데이터를 train 용, test 용으로 분류한다.\n",
        "            2. LSTM모델 사용을 위해 3차원 텐서로 데이터를 재구성한다.\n",
        "    입력: \n",
        "            1. plot_df            : 이전에 정리한 데이터\n",
        "            2. time step\n",
        "            3. period\n",
        "            4. j 번째 feature\n",
        "    출력 :  \n",
        "            1. X_train, y_train           :  2015.08.24 ~ 2021.06.30 의 데이터\n",
        "            2. X_test, y_test             :  2021.07.01 ~ 2022.07.01 의 데이터\n",
        "    \"\"\"\n",
        "    # train용, test용 데이터 분리\n",
        "                                                                                # 2021.07.01 ~ 2022.07.01 의 영업일은 247일\n",
        "                                                                                # 2015.08.24 ~ 2022.07.01 의 영업일은 1686일\n",
        "    ts_train = all_data[:-248].iloc[:,j].values                                 # ts_train 데이터 : 2015.08.24 ~ 2021.06.30  데이터   2 차원    \n",
        "                                                                                # ex) array([['0.201438','0.019713', '0.031785', '0.8'], ['0.210541','0.019713','0.031785','0.8'], ... , ]])                               \n",
        "    ts_test = all_data[-247:-1].iloc[:,j].values                                          # ts_test  데이터 : 2021.07.01 ~ 2022.07.01 데이터    2 차원\n",
        "    \n",
        "    # train용 데이터를 samples와 tiem_steps로 슬라이싱하기 (5일 간격으로 1일 예측을 학습)\n",
        "    X_train = []                                                                # X_train : 5일 치씩 3차원 묶음 데이터\n",
        "    y_train = []                                                                # y_train : X_train에서 이어지는 1일 치씩 3차원 데이터\n",
        "    #y_train_stacked = []\n",
        "                                                                                # time_steps : 5\n",
        "                                                                                # for_periods : 1\n",
        "\n",
        "    for i in range(time_steps,len(ts_train) - 1):                               # for 문 : KOSPI_ts_train 데이터를 time_steps(사이즈:5 day)가 1회 훑고 갈동안 반복한다.\n",
        "        X_train = np.append(X_train, ts_train[i - time_steps : i])              # t일~t+4일 배열 ~ 을 X_train에 append                              ex) [ts_train[0],[1],[2],[3],[4], ts_train[1],[2],[3],[4],[5], ... ]                 \n",
        "        y_train = np.append(y_train, ts_train[i: i + for_periods])              # X_train의 다음 데이터(t + 5 일)배열을 1일 씩 y_tran에 append      ex) [KOSPI_ts_train[5], KOSPI_ts_train[6],  ... tKOSPI_s_train[251]]\n",
        "    X_train = np.array(X_train)                                                 # X_train 배열을 numpy 배열로 만든다    .                          \n",
        "    y_train = np.array(y_train)                                                 # y_train 배열을 numpy 배열로 만든다.   \n",
        "    # 2차원 텐서로 재구성\n",
        "    # np.reshapes(samples, time_steps, features)로 재구성\n",
        "    X_train = np.reshape(X_train,(-1, 5))                                       # X_train : (X_train의 행의 개수, X_train의 열의 개수, feature = 1)    \n",
        "\n",
        "    # X_test 생성\n",
        "    inputs = all_data.iloc[:,j].values                                          # inputs 데이터: ['0.2014', '0.2105', ..., '0.XXX']\n",
        "    inputs = inputs[len(inputs)-len(ts_test) - time_steps:]                     # inputs 데이터: 2021.07.01 ~ 2022.07.01의 데이터 \n",
        "    inputs = inputs.reshape(-1,1)                                               # reshape      : 행: -1, 열: 1  :  [['0.2014'], ['0.2105'], ..., ['0.XXX']]\n",
        "    \n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    for i in range(time_steps, len(ts_test)+ time_steps- for_periods):          # time_stemps 만큼씩 데이터 묶음을 만든다.\n",
        "        X_test.append(inputs[i-time_steps:i])\n",
        "        y_test.append(inputs[i])\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "    #print(\"\\n\\n ytest = \", y_test)\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]))\n",
        "    #print('X_train : ', X_train, '\\n, y_train: ' , y_train , '\\n, X_test: ', X_test)\n",
        "    return X_train, y_train, X_test, y_test                                             # return : 생성돤 X_train, y_train, X_test 값을 반환\n",
        "\n",
        "#'KOSPI','NASDAQ','CPI', 'M2'\n",
        "KOSPI_X_train, KOSPI_y_train, KOSPI_X_test, KOSPI_y_test           = third_dimensionize(plot_df, 5, 1,0)   #KOSPI      #(데이터프레임. time_steps, for_periods, j열)\n",
        "NASDAQ_X_train, NASDAQ_y_train, NASDAQ_X_test, NASDAQ_y_test       = third_dimensionize(plot_df, 5, 1,1)   #NASDAQ\n",
        "CPI_X_train, CPI_y_train, CPI_X_test, CPI_y_test                   = third_dimensionize(plot_df, 5, 1,2)   #CPI\n",
        "M2_X_train, M2_y_train, M2_X_test, M2_y_test                       = third_dimensionize(plot_df, 5, 1,3)   #M2\n",
        "Gov_Exp_X_train, Gov_Exp_y_train, Gov_Exp_X_test, Gov_Exp_y_test   = third_dimensionize(plot_df, 5, 1,3)   #Gov_Exp\n",
        "HANGSENG_X_train, HANGSENG_y_train, HANGSENG_X_test, HANGSENG_y_test                           = third_dimensionize(plot_df, 5, 1,3)   #HANGSENG\n",
        "Interest_Gap_X_train, Interest_Gap_y_train, Interest_Gap_X_test, Interest_Gap_y_test           = third_dimensionize(plot_df, 5, 1,0)   #interest_gap\n",
        "Est_Vol_X_train, Est_Vol_y_train, Est_Vol_X_test, Est_Vol_y_test                               = third_dimensionize(plot_df, 5, 1,0)   #Est_Vol\n",
        "\n",
        "#이상으로 2차원 리스트 획득\n",
        "#여기서 y train은 코스피 하나만 필요할 것 같다고 생각됨\n",
        "\n",
        "# 2차원 리스트를3차원 텐서로 데이터 결합\n",
        "print(\"KOSPI len\", len(KOSPI_X_train))        \n",
        "Temp1 = np.empty((0,5)) \n",
        "Temp2 = np.empty((0,5)) \n",
        "#X_train = np.empty((0,4,5))                                                     # 1432\n",
        "X_train = []\n",
        "X_test  = []\n",
        "#print('X_train', X_train.shape)\n",
        "\n",
        "\n",
        "for i in range (len(KOSPI_X_train)):                                            # 1432번 반복\n",
        "    #print('X_train', X_train)\n",
        "    Temp1 = np.append(Temp1, np.array([KOSPI_X_train[i]]), axis = 0)\n",
        "    Temp1 = np.append(Temp1, np.array([NASDAQ_X_train[i]]), axis = 0)\n",
        "    Temp1 = np.append(Temp1, np.array([CPI_X_train[i]]), axis = 0)\n",
        "    Temp1 = np.append(Temp1, np.array([M2_X_train[i]]), axis = 0)               # Temp1 : [[0.20111, 0.21XXXX , 0.21XXX, 0.21XXX, 0.21XXX], [0.01973, 0.01973, 0.01973, 0.01973, 0.01973], [...], [...]]\n",
        "    Temp1 = np.append(Temp1, np.array([Gov_Exp_X_train[i]]), axis = 0)\n",
        "    Temp1 = np.append(Temp1, np.array([HANGSENG_X_train[i]]), axis = 0)\n",
        "    Temp1 = np.append(Temp1, np.array([Interest_Gap_X_train[i]]), axis = 0)\n",
        "    Temp1 = np.append(Temp1, np.array([Est_Vol_X_train[i]]), axis = 0)\n",
        "    print('Temp1', Temp1)\n",
        "    #Temp1 = [KOSPI_X_train[i], NASDAQ_X_train[i], CPI_X_train[i], M2_X_train[i]]\n",
        "    #print(Temp1)\n",
        "    #X_train = np.append(X_train, np.array([[Temp1]]), axis = 0)\n",
        "    X_train.append(Temp1) \n",
        "    Temp1 = np.empty((0,5))                  \n",
        "for i in range (len(KOSPI_X_test)):                                            # 1432번 반복\n",
        "    #print('X_train', X_train)\n",
        "    Temp2 = np.append(Temp2, np.array([KOSPI_X_test[i]]), axis = 0)\n",
        "    Temp2 = np.append(Temp2, np.array([NASDAQ_X_test[i]]), axis = 0)\n",
        "    Temp2 = np.append(Temp2, np.array([CPI_X_test[i]]), axis = 0)\n",
        "    Temp2 = np.append(Temp2, np.array([M2_X_test[i]]), axis = 0)               # Temp2 : [[0.20111, 0.21XXXX , 0.21XXX, 0.21XXX, 0.21XXX], [0.01973, 0.01973, 0.01973, 0.01973, 0.01973], [...], [...]]\n",
        "    Temp2 = np.append(Temp2, np.array([Gov_Exp_X_test[i]]), axis = 0)\n",
        "    Temp2 = np.append(Temp2, np.array([HANGSENG_X_test[i]]), axis = 0)\n",
        "    Temp2 = np.append(Temp2, np.array([Interest_Gap_X_test[i]]), axis = 0)\n",
        "    Temp2 = np.append(Temp2, np.array([Est_Vol_X_test[i]]), axis = 0)\n",
        "    print('Temp2', Temp2)\n",
        "    X_test.append(Temp2) \n",
        "    Temp2 = np.empty((0,5))  \n",
        "\n",
        "y_train = KOSPI_y_train\n",
        "y_test  = np.array(KOSPI_y_test)\n",
        "y_test = np.ravel(y_test, order ='C')\n",
        "#X_test = np.array([KOSPI_X_test, NASDAQ_X_test, CPI_X_test, M2_X_test])\n",
        "#KOSPI_y_train  = np.reshape(KOSPI_y_train, (KOSPI_y_train[0],1))\n",
        "X_train = np. array(X_train)\n",
        "X_test = np. array(X_test)\n",
        "\n",
        "print(\"\\nreal_X_train\" ,   X_train)\n",
        "print(\"\\nreal_y_train\" ,   y_train)\n",
        "\n",
        "print(\"\\nreal_X_test\" ,   X_test)\n",
        "print(\"\\nreal_y_test\" ,   y_test)\n",
        "\n",
        "\n",
        "print(\"\\n\\nX_train shape\",X_train.shape)\n",
        "print(\"y_train.shape\" ,   y_train.shape)\n",
        "print(\"X_test.shape\" ,    X_test.shape)\n",
        "print(\"y_test.shape\" ,    y_test.shape)\n",
        "# 결과:\n",
        "# X_train 3차원 텐서 : real_X_train\n",
        "# y_train 1차원 리스트 : real_y_train                                           # ex)  [0.26188453 0.24713001 0.24766585 ... 0.98965668 0.99871723 0.99820305] \n",
        "# X_test 3차원 텐서 : real_X_test\n",
        "# y_test 1차원 리스트 : real_y_test\n",
        "'''\n",
        "    원하는 X_train의 결과: array([\n",
        "\n",
        "                                            [[KOSPI_day1, KOSPI_day2, KOSPI_day3, KOSPI_day4, KOSPI_day5],\n",
        "                                            [NASDAQ_day1, NASDAQ_day2, NASDAQ_day3, NASDAQ_day4, NASDAQ_day5],\n",
        "                                            [CPI_day1, CPI_day2, CPI_day3, CPI_day4, CPI_day5],\n",
        "                                            [M2_day1, M2_day2, M2_day3, M2_day4,  M2_day5]],\n",
        "\n",
        "                                            [[KOSPI_day2, KOSPI_day3, KOSPI_day4, KOSPI_day5, KOSPI_day6],\n",
        "                                            [NASDAQ_day2, NASDAQ_day3, NASDAQ_day4, NASDAQ_day5, NASDAQ_day6],\n",
        "                                            [CPI_day2, CPI_day3, CPI_day4, CPI_day5, CPI_day6],\n",
        "                                            [M2_day2, M2_day3, M2_day4, M2_day5, M2_day6]],\n",
        "\n",
        "                                            ...\n",
        "\n",
        "                                            [[KOSPI_day1XXX, KOSPI_day1XXX, KOSPI_day1XXX, KOSPI_day1XXX],\n",
        "                                            [NASDAQ_day1XXX, NASDAQ_day1XXX, NASDAQ_day1XXX, NASDAQ_day1XXX],\n",
        "                                            [CPI_day1XXX, CPI_day1XXX, CPI_day1XXX, CPI_day1XXX],\n",
        "                                            [M2_day1XXX, M2_day1XXX, M2day1XXX, M2_day1XXX]]\n",
        "\n",
        "                                    ])\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J27oW-ETGgKC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHqU3eQxEeUM"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9oYEkQe9bRY"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.layers import LSTM, GRU,SimpleRNN\n",
        "\n",
        "# CNN - LSTM model setting\n",
        "CNN = Sequential()                                                              # Sequential : 레이어를 선형으로 구성\n",
        "CNN.add(LSTM(512, input_shape = (X_train.shape[1], X_train.shape[2])))          # many-to-many 의 경우 return_sequences = True (default : False), tanh: -1~ +1\n",
        "                                                                                # input_shape: (6,5) \n",
        "                                                                                # timp_steps: 5, units: 1\n",
        "CNN.add(Dense(256, activation = 'relu'))   \n",
        "#CNN.add(Dropout(0.3))\n",
        "CNN.add(Dense(64, activation = 'relu'))   \n",
        "#CNN.add(Dropout(0.3))\n",
        "CNN.add(Dense(16, activation = 'relu'))  \n",
        "#CNN.add(Dropout(0.3)) \n",
        "CNN.add(Dense(1))                                                               # The time step of the output \n",
        "CNN.summary()                                                                   # model summary\n",
        "\n",
        "# model compile                                                                \n",
        "CNN.compile(optimizer= 'adam', loss = 'mean_squared_error',metrics='acc') # optimizer : adam, loss : MSE. 예측한 값과 실제 값 사이의 평균 제곱 오차를 정의한다. 차이가 커질수록 제곱 연산으로 인해 오차가 양수이든 음수이든 누적 값을 증가시킨다.\n",
        "                                                                                \n",
        "# model fitting\n",
        "CNN.fit(X_train, y_train, epochs = 30, batch_size = 100)                        # epoch = 전체 트레이닝 셋이 신경망을 통과한 횟수. (전체 데이터 셋에서 전체 데이터를 N 번 학습)\n",
        "# model prediction                                                              # batch_size = 한 번의 batch마다 주는 데이터 샘플의 size\n",
        "CNN_predictions = CNN.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSivHzbtkdX8"
      },
      "outputs": [],
      "source": [
        "# 실제 KOSPI 결과와 LSTM 예측 결과를 그래프로 표시\n",
        "def actual_pred_plot(preds):\n",
        "    \"\"\"\n",
        "    Plot the actual vs predition\n",
        "    \"\"\"\n",
        "    actual_pred = pd.DataFrame(columns = ['KOSPI', 'prediction'])\n",
        "    actual_pred['KOSPI'] = y_test\n",
        "    actual_pred['prediction'] = preds[:,0]\n",
        "    \n",
        "    from keras.metrics import MeanSquaredError \n",
        "    m = MeanSquaredError()\n",
        "    m.update_state(np.array(actual_pred['KOSPI']), np.array(actual_pred['prediction']))\n",
        "    \n",
        "    return (m.result().numpy(), actual_pred.plot())\n",
        "\n",
        "actual_pred_plot(CNN_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN_prediction_real = CNN_predictions *"
      ],
      "metadata": {
        "id": "YZF5j_oNmaxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz6MJtyIvsPn"
      },
      "outputs": [],
      "source": [
        "#예측한 KOSPI값들 2021.07.01~2022.07.01\n",
        "CNN_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PySO_XY_xP-w"
      },
      "outputs": [],
      "source": [
        "#실제 KOSPI값들 2021.07.01~2022.07.01\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBgbgB1sBFHy"
      },
      "outputs": [],
      "source": [
        "CNN.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VszpVHFUxTte"
      },
      "outputs": [],
      "source": [
        "# 예측 성능 확인\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
        "def confirm_result(y_test, CNN_predictions):\n",
        "    MAE = mean_absolute_error(y_test, CNN_predictions)\n",
        "    RMSE = np.sqrt(mean_squared_error(y_test, CNN_predictions))\n",
        "    MSLE = mean_squared_log_error(y_test, CNN_predictions)\n",
        "    RMSLE = np.sqrt(mean_squared_log_error(y_test, CNN_predictions))\n",
        "    R2 = r2_score(y_test, CNN_predictions)\n",
        "\n",
        "    pd.options.display.float_format = '{:.5f}'.format\n",
        "    Result = pd.DataFrame(data = [MAE, RMSE, MSLE, RMSLE, R2],\n",
        "                          index = ['MAE', 'RMSE', 'MSLE','RMSLE', 'R2'],\n",
        "                          columns=['Results'])\n",
        "    return Result\n",
        "confirm_result(y_test, CNN_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Review**"
      ],
      "metadata": {
        "id": "nj4C_yqgq9jy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**박수영**<br>\n",
        "  이번 학기에 '인공지능 기초와 활용' 교과목을 배우면서 실생활에 사용할 수 있는지가 궁금했다. 좋은 기회라 판단하여 본 프로젝트에 참여하였다. 수업시간에 배운 RNN, CNN, 자연어 처리 등을 사용하고자 하였다. 처음에는 증권사 API를 사용하려고 컴퓨터에 증권사 프로그램도 설치 해보고 계좌도 만들며 어려운 시간을 보냈다. 결국 코랩이라는 플랫폼을 사용하였다. 이 유능한 딥러닝 플랫폼을 개발한 구글에 감사를 표하고 싶다. \n",
        "<br>제일 먼저 한 것을 경제 지표를 크롤링하는 것이 었는데, 수업시간에 배우는 자료구조와 같이 이론적인 것 프로그래밍 밖에 몰랐던 내게는 첫 번쨰, 고비였다. 참고자료들을 참고해서 필요에 맞게 적용했다. 두 번쨰는 수집한 데이터를 가공하는 일이다. 내가 원하는 목적으로 데이터를 가공하기 위해 많은 시간을 보냈고 어려웠다. 세 번째로 한 것은 기존 수업시간에 배웠던 인공지능 모델 (LSTM)을 사용해 학습을 시키는 것이다. 학습결과는 언뜻 보기에는 정확도가 높아보이나, 전일의 데이터를 오른 쪽으로 밀어놓은 것 같은 그래프를 얻었다. 이는 인공지능 모델이 Loss를 줄이기 위해 익일의 데이터가 금일과 동일하다고 가정했기 때문으로 추정된다. 약 3달 정도의 KOSPI주가를 예측하고자 하였지만, 프로젝트의 결과는 실용적이지 못했다. 이 점이 가장 아쉬웠다. KOSPI지수 예측이 더 실용적이기 위해서는 인공지능 모델의 손실 및 학습 구조에 근본적인 해결책을 찾아야 할 것이다.이 프로젝트를 통해 이론으로만 알고있었던 딥러닝을 실제 사회에 적용해 볼 수 있었다. 또한, 내가 모르던 경제 분야를 간접적으로 배울 수 있어 협업과 교류의 중요성을 알 수 있었다.\n",
        "<font color=\"Yellow\"></font>\n",
        "<br>\n",
        "<br>\n",
        "**이동환** <br>\n",
        " '금융통계'라는 과목을 마지막 학기에 들으며 금융자산으로부터 정량적인 통계치를 얻어내는 여러 방식을 접했다. 이후 금융자산을 평가하기 위한 더욱 다양하고 심화된 방법들에 대해 검색해 보던 중, 최근 몇 년간 화제가 되었던 딥러닝과 머신러닝 등의 기법들을 적용할 수 있음을 알게 되었고, 이것들을 금융 시계열 데이터에 적용하면 어떤 장점이 있고 기존의 시계열 모형에 비해 어떠한 우위를 갖는지에 대해 직접 구현을 통해 확인해보고 싶었다.<br>\n",
        "\n",
        " 비전공자로서의 한계로, 모델을 구성하고 딥러닝을 시키는 과정에 직접적으로 참여하기 힘들었지만, 실제 내가 구성한 데이터를 가지고 텐서를 구성하고, 모델을 설정하며 학습을 시키는 일련의 과정을 눈으로 확인해 보면서 아예 잘 몰랐던 분야에 대해 이해도를 높이는 좋은 시간이 되었다."
      ],
      "metadata": {
        "id": "gOhm6PX9rJZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**9. 참고 자료 (Reference)**"
      ],
      "metadata": {
        "id": "oHvK6nWTZYZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학술 - LSTM을 이용한 주가예측 모델의 학습방법에 따른 \n",
        "성능분석 (정종진, 김지연)<br><br>\n",
        "학술 - 머신 러닝 방법과 시계열 분석 모형을 이용한 \n",
        "부동산 가격지수 예측(배성완, 유정석)\n",
        "<br><br>\n",
        "학술 - SNS와 뉴스기사의 감성분석과 기계학습을 이용한 주가예측 모형에 관한 연구 (김동영)<br><br>\n",
        "학술 - LSTM과 양방향 순환신경망을 이용한 주가 예측모델 비교연구 (이종혁)\n",
        "도서 - 밑바닥부터 시작하는 딥러닝<br><br>\n",
        "도서 - 코딩은 처음이라 with 딥러닝<br><br>\n",
        "도서 - 토닥토닥 파이썬 - 머신 러닝 추가문제: https://wikidocs.net/book/3682<br><br>\n",
        "도서 - 파이썬으로 배우는 알고리즘 트레이딩 (개정판-2쇄): https://wikidocs.net/book/110<br><br>\n",
        "도서 - 퀀트 전략을 위한 인공지능 트레이딩<br><br>\n",
        "블로그 - [시계열] 주가 예측을 위한 RNN/LSTM/GRU 기술적 가이드 : https://diane-space.tistory.com/331<br><br>\n",
        "블로그 - [머신러닝 입문]-5 회귀(Regression)-보스턴 주택가격예측 : https://liz09045.tistory.com/95<br><br>\n",
        "블로그 - 딥러닝 초보들의 실수:https://codingapple.com/unit/deep-learning-stock-price-ai/<br><br>\n",
        "블로그 - 신경망(딥러닝) : https://tensorflow.blog/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2-3-8-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EB%94%A5%EB%9F%AC%EB%8B%9D/<br><br>\n",
        "블로그 - [LSTM] Understanding Input And Output Shapes (LSTM 입출력 Shapes) : https://kimmisol.com/lstm-understanding-input-and-output-shapes-lstm-%EC%9E%85%EC%B6%9C%EB%A0%A5-shapes/<br><br>\n",
        "\n",
        "블로그 - 시계열 예측: LSTM 모델로 주가 예측하기 : https://insightcampus.co.kr/2021/11/11/%EC%8B%9C%EA%B3%84%EC%97%B4-%EC%98%88%EC%B8%A1-lstm-%EB%AA%A8%EB%8D%B8%EB%A1%9C-%EC%A3%BC%EA%B0%80-%EC%98%88%EC%B8%A1%ED%95%98%EA%B8%B0/<br><br>\n",
        "블로그 - 다중공선성과 변수 선택 : https://datascienceschool.net/03%20machine%20learning/06.04%20%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1%EA%B3%BC%20%EB%B3%80%EC%88%98%20%EC%84%A0%ED%83%9D.html<br><br>\n",
        "블로그 - RNN에 들어가는 데이터 input shape : https://wyatt37.tistory.com/13<br><br>\n",
        "\n",
        "블로그 - Time-Series Forecasting: Predicting Stock Prices Using An ARIMA Model: https://towardsdatascience.com/time-series-forecasting-predicting-stock-prices-using-an-arima-model-2e3b3080bd70<br><br>\n",
        "블로그 - [LSTM/GRU]주식가격 예측 모델 구현하기 https://data-analysis-expertise.tistory.com/67<br><br>\n",
        "\n",
        "블로그 - 주식 분석 개발환경 설정 - 파이썬 환경 설정 및 실행 : https://excelsior-cjh.tistory.com/105<br><br>\n",
        "\n",
        "블로그 - 딥러닝 Keras에서 loss함수의 종류와 선택 방법 및 코드 : https://durian9s-coding-tree.tistory.com/2<br><br>\n",
        "\n",
        "블로그 - 왜 직관적인 MAE 말고 RMSE를 쓰시나요 : https://data101.oopy.io/mae-vs-rmse<br><br>\n",
        "블로그 - iloc, loc를 사용한 행/열 선택법 from Pandas df : https://azanewta.tistory.com/34<br><br>\n",
        "\n",
        "깃허브 - GJR-GARCH model : https://github.com/olekssy/quant-finance/blob/master/tutorials/GJR-GARCH.ipynb<br><br>\n",
        "깃허브 - ARIMA, Python으로 하는 시계열분석 (feat. 비트코인 가격예측)\n",
        " : https://byeongkijeong.github.io/ARIMA-with-Python/<br><br>\n",
        "깃허브 - 한국 주식 및 암호화폐까지 데이터 요청 :\n",
        "https://financedata.github.io/posts/finance-data-reader-users-guide.html<br><br>\n",
        "기타 - 서울시립대학교 교양교과목 \"인공지능기초와활용\" 교육자료\n"
      ],
      "metadata": {
        "id": "P8jJjZrqaQX1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmmImmSqEmxR"
      },
      "source": [
        "#**10.  도서 '퀀트 전략을 위한 인공지능 트레이딩' 요약 (Referenced Book Summary)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpHPUoZMzJAz"
      },
      "outputs": [],
      "source": [
        "#                                   '퀀트 전략을 위한한 인공지능 트레이딩' 요약\n",
        "#\n",
        "#   데이터처리과정\n",
        "#\n",
        "#   1.RAW data 불러오기 (Ok.)\n",
        "#   2.Data 가공 및 결합하기 (Ok.)\n",
        "#   3.훈련,검증,테스트 데이터셋 분리하기 (To Do)\n",
        "#   4.학습에 용이하도록 데이터 정규화(min-max normal)하기 (To Do)\n",
        "#   5.특성 데이터, 레이블 데이터 나누기 (To Do)\n",
        "#\n",
        "#   1장 - 머신러닝   #\n",
        "##########################################################################################################\n",
        "#   금융데이터 머신러닝 알고리즘 : 지도학습(SVM/Random Forest/부스팅/XGBoost/LightGBM/CatBoost) -> 금융에서 부스팅보다 배깅이 선호된다고 한다.\n",
        "#                           비지도 학습 - 차원 축소와 클러스터링\n",
        "#\n",
        "#   교차검증법 k-fold/walk-forward/blocking walk-forward, 퍼징/엠바고\n",
        "#\n",
        "#   금융시계열데이터 전처리 (노이즈제거) -> 오토인코더 추천 (적층오토인코더 Stacked AutoEncoder) 활용 -> 업계표준이라고 함.\n",
        "#\n",
        "#   평가지표 : 정확도/정밀도/F1/AUC-ROC. 회귀시 MSE, R-squared (52~56% 정도의 정확도가 적절하다고 합니다.)\n",
        "#\n",
        "#   머신러닝 시계열 트렌드 예측시 : 레이블 데이터 +1 or -1 레이블링 <- 비합리적\n",
        "#                            상승률에 따라 다른 가중치 부여 (이진 분류 -> 다중 분류)\n",
        "#   레이블 데이터 불균형 문제 : 시장 상황에 따른 데이터 불균형 문제 (ex: 주가상승기 모델링 -> 실제 적용시 경기하강국면이라면 문제가 된다)\n",
        "#                         등락 횟수가 비슷하게 레이블링을 하거나, AUC-ROC 같은 측정지표를 활용해본다.\n",
        "#   수익률 지표 : 산술평균보다 기하평균수익률이 적절. (cf: 기하평균 => exp[Sigma[log(1+Rt)]의 * n분의 1]), Rt: t시점 수익률\n",
        "#\n",
        "#\n",
        "#   백테스팅 : 최소 10넌 데이터...??? 가 적절.. , 그러나 시장 상황이 과거와 비슷하게 돌아간다는 가정은 비현실적이기 백테스팅 맹신은 위험\n",
        "#            최대한 많은 경제적 시나리오를 포함하는 백테스팅 기간 설정\n",
        "#           (이 부분은 제가 생각해 볼게요. 최근 1년 동안 꾸준한 하락장이라 데이터에 편향이 있을 것 같네요.)\n",
        "#   수수료 + 슬리피지(시장 주문량에 따라 일정 가격으로 주문할 수 있는 양이 제한됨) 문제 고려\n",
        "#   편향 : 생존편향(상폐당하지 않은 종목만 고려하여 백테스팅)\n",
        "#         사전관찰편향(3월의 경제지표가 4월말에 발표되는 문제) <- 이건 fillna (ffill/bfill)순서활용해서 조정해볼게요.\n",
        "#\n",
        "#   전체 자산 종류나 투자 영역에 대한 모델 개발이 좋다.(이 지점에서 코스피를 먼저 분석하는게 좋은 것 같아요. 모든 주식을 포함하니까요)\n",
        "#   여러가지 지표 : 수익률 외 변동성/샤프비율/최대 낙폭/소르티노지수/트레이너지수/젠센의 알파\n",
        "##########################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "#   2장 - 딥러닝 개괄  #\n",
        "##########################################################################################################\n",
        "#   사이킷런 활용 전 치트시트를 한 번 확인해보자.\n",
        "#   CNN : 1D - 합성곱 방법을 쓰거나, 수치데이터를 이미지데이터로 변환 후 분석.\n",
        "#   RNN : 순환 신경망, 역전파 사용 -> 데이터가 너무 길어지면 그래디언트 작아져 학습이 안되는 문제 -> LSTM으로 해결\n",
        "#         주가 데이터에 LSTM 추천, but 패턴이 없는 주가의 경우 RNN이 학습하기 어려울 수도  [매우 장기의 데이터라면면 패턴턴 발견견 될될 수도]\n",
        "#   비지도학습 : 오토인코더가 대표적(Sparse,Denoising,Contractive...오토인코더) 벡터 X 입력 후 유사 벡터 X출력, 입출력 노드 개수 같음\n",
        "\n",
        "#   생성모델 : GAN(적은 데이터로 효과적) / VAE(못지않게 자주 활용) / Hidden Markov Model\n",
        "#\n",
        "#   연구논문   [Financial Time Series Forecasting with Deep Learning: A Systemic Literature Review: 2005~2019]\n",
        "#            요약 : 'RNN의 LSTM이 우위지만, 머신러닝이 더 성능이 좋을 수도 있다.\n",
        "#\n",
        "#   퀀트피디아 사이트 : www.quantpedia.com\n",
        "#\n",
        "#   모듈 : 케라스 > 텐서플로, 파이토치 순으로 어렵다.\n",
        "#\n",
        "##########################################################################################################\n",
        "\n",
        "#   3장 - 딥러닝 이용 투자전략  #\n",
        "##########################################################################################################\n",
        "#   주가 캔들차트를 차원축소 이미지로 변환, 이미지 데이터 분석에 뛰어난 CNN으로 학습하는 예제\n",
        "#   논문 : Using Deep Learning Neural Networks and Candlestick Chart Representation to Predict Stock Market\n",
        "#   \n",
        "#   모델구조 짜기 : 케라스의 \"함수형 API\"를 활용, 신경망 모델을 생성한다.\n",
        "#   모델 학습하기\n",
        "#\n",
        "#   RNN,LSTM을 활용한 주가 방향성 분류 예측\n",
        "#   논문 : Application of Deep Learning to Algorithmic Trading(2017)\n",
        "#\n",
        "#   특징 : 변수 3개 활용, 시장 인덱스 S&P 500, 변동성 지수 VIX, 반도체 지수 SOX\n",
        "#   데이터 구조 : 497묶음 of (특성 22개 x 5일치)\n",
        "#   모델구조 : LSTM(케라스 지원, 5개 층, 200개 뉴런)\n",
        "#   모델 학습 : ...\n",
        "#\n",
        "#   오토인코더를 활용한 주가 데이터 생성\n",
        "#   특징 : x개 변수 input, x개 변수 output\n",
        "#   데이터 처리 : 수정 종가 이용 로그수익률 데이터, 정규화\n",
        "#   데이터 구조 : 5023묶음 of (특성 1개, 10일치)\n",
        "#   모델 구조 : 다층 퍼셉트론(MLP), 다충 퍼셉트론 모델에 배치층 추가(인코더 : 차원 축소층, 디코더 : 차원 확장층)\n",
        "##########################################################################################################\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "KOSPI 예측 프로젝트.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}